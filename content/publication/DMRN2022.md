---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Large-Scale Pretrained Model for Self-Supervised Music Audio Representation Learning"
subtitle: ""
summary: ""
authors: []
tags: ["SSL", "MIR"]
categories: []
date: 2022-12-19T18:24:35+01:00
lastmod: 2023-09-29T18:24:35+01:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: ["mert"]
---
Abstract: Self-supervised learning technique is an under-explored topic for music audio due to the challenge of designing an appropriate training paradigm. We hence propose MAP-MERT, a large-scale music audio pre-trained model for general music understanding. We achieve performance that is comparable to the state-of-the-art pre-trained model Jukebox using less than 2% of parameters.

- <a href="https://qmro.qmul.ac.uk/xmlui/handle/123456789/83372" target="_blank">Paper link.</a>

- Presented by DMRN workshop 2022.