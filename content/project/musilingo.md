---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Bridging Music & Text with Pre-trained Models for Music Captioning and QA"
subtitle: ""
summary: ""
authors: []
tags: ["SSL", "MIR", "Multimodal", "datasets"]
categories: []
date: 2023-09-29T21:40:17+01:00
lastmod: 2023-09-29T21:40:17+01:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---
07/2023 â€“ present

Supervised by Dr Emmanouil Benetos, Centre for Digital Music, Queen Mary University of London
- Developed Music Instruct (MI) query-response dataset based on captions & well-designed prompts to GPT-4.
- Achieved cutting-edge performance in question answering on both MusicQA and Music Instruct datasets.
- Employed instruct fine-tuning techniques on MI to attain state-of-the-art (SOTA) results in captioning.