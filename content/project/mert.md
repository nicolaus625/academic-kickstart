---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised TrainingCCF none"
subtitle: ""
summary: ""
authors: []
tags: ["MIR", "Deep Learning", "SSL"]
categories: []
date: 2023-09-29T21:40:17+01:00
lastmod: 2023-09-29T21:40:17+01:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---
08/2022 â€“ 05/2023

Supervised by Dr Emmanouil Benetos, Centre for Digital Music, Queen Mary University of London

- Built self-supervised learning systems, acquiring 50k+ downloading of checkpoints on Huggingface.
- Replaced the pseudo-tag from MFCCs to Chroma music features for harmonic information.
- Utilising deep features like Encodec instead of k-means for scaling up models to 1 B parameters.